<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Speech API Demo</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }
        
        .container {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        h1 {
            text-align: center;
            color: #4a5568;
            margin-bottom: 30px;
        }
        
        .section {
            margin-bottom: 30px;
            padding: 20px;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            background: #f8fafc;
        }
        
        button {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
            transition: all 0.3s ease;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        button:disabled {
            background: #cbd5e0;
            cursor: not-allowed;
            transform: none;
        }
        
        textarea {
            width: 100%;
            min-height: 100px;
            padding: 15px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 16px;
            font-family: inherit;
            resize: vertical;
        }
        
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .listening {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        select {
            padding: 8px 12px;
            border: 2px solid #e2e8f0;
            border-radius: 5px;
            font-size: 14px;
        }
        
        .recording {
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            border-top: 2px solid #e2e8f0;
            color: #666;
            font-size: 14px;
        }
        
        .footer .heart {
            color: #e53e3e;
            animation: heartbeat 1.5s ease-in-out infinite;
        }
        
        .footer .github-icon {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 32px;
            height: 32px;
            margin: 10px auto 0;
            background: #333;
            border-radius: 50%;
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
        }
        
        .footer .github-icon:hover {
            background: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        .footer .github-icon svg {
            width: 18px;
            height: 18px;
        }
        
        @keyframes heartbeat {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>ğŸ¤ Web Speech API Demo</h1>
        
        <!-- Windows Virtual Audio Setup Guide -->
        <div class="section" style="background: #f8f9fa; border: 2px solid #dee2e6;">
            <h2>ğŸ–¥ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Windows</h2>
            
            <div style="margin-bottom: 20px; padding: 15px; background: #e7f3ff; border-radius: 8px; border-left: 4px solid #0066cc;">
                <h3 style="margin-top: 0; color: #0066cc;">ğŸ”§ Ø±ÙˆØ´ 1: ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Stereo Mix (Ø±Ø§ÛŒÚ¯Ø§Ù†)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># Ø¨Ø§Ø² Ú©Ø±Ø¯Ù† Sound Settings</div>
                    Win + R â†’ mmsys.cpl â†’ Enter<br><br>
                    
                    <div style="color: #98c379;"># ÙØ¹Ø§Ù„â€ŒØ³Ø§Ø²ÛŒ Stereo Mix</div>
                    1. ØªØ¨ "Recording" â†’ Right Click â†’ "Show Disabled Devices"<br>
                    2. "Stereo Mix" â†’ Right Click â†’ "Enable"<br>
                    3. "Stereo Mix" â†’ Right Click â†’ "Set as Default Device"<br><br>
                    
                    <div style="color: #98c379;"># ØªÙ†Ø¸ÛŒÙ… Volume</div>
                    4. "Stereo Mix" â†’ Double Click â†’ Levels â†’ 70-80%<br>
                    5. Advanced â†’ 16 bit, 44100 Hz â†’ OK
                </div>
            </div>

            <div style="margin-bottom: 20px; padding: 15px; background: #fff3cd; border-radius: 8px; border-left: 4px solid #ffc107;">
                <h3 style="margin-top: 0; color: #856404;">ğŸ› ï¸ Ø±ÙˆØ´ 2: VB-Audio Virtual Cable (Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># Ø¯Ø§Ù†Ù„ÙˆØ¯ Ùˆ Ù†ØµØ¨</div>
                    1. Download: https://vb-audio.com/Cable/<br>
                    2. Extract â†’ Run as Administrator â†’ Install<br>
                    3. Restart Windows<br><br>
                    
                    <div style="color: #98c379;"># ØªÙ†Ø¸ÛŒÙ…Ø§Øª</div>
                    4. Sound Settings â†’ Output â†’ "CABLE Input"<br>
                    5. Sound Settings â†’ Input â†’ "CABLE Output"<br>
                    6. Volume: 80-90%
                </div>
            </div>

            <div style="margin-bottom: 20px; padding: 15px; background: #d1ecf1; border-radius: 8px; border-left: 4px solid #17a2b8;">
                <h3 style="margin-top: 0; color: #0c5460;">ğŸµ Ø±ÙˆØ´ 3: VoiceMeeter (Ø­Ø±ÙÙ‡â€ŒØ§ÛŒ)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># Ù†ØµØ¨ VoiceMeeter</div>
                    1. Download: https://vb-audio.com/Voicemeeter/<br>
                    2. Install â†’ Restart<br><br>
                    
                    <div style="color: #98c379;"># ØªÙ†Ø¸ÛŒÙ…Ø§Øª</div>
                    3. Windows Sound â†’ Output â†’ "VoiceMeeter Input"<br>
                    4. Windows Sound â†’ Input â†’ "VoiceMeeter Output"<br>
                    5. VoiceMeeter â†’ A1: Default speakers<br>
                    6. B1: Enable for routing
                </div>
            </div>

            <div style="padding: 15px; background: #d4edda; border-radius: 8px; border-left: 4px solid #28a745;">
                <h3 style="margin-top: 0; color: #155724;">âœ… ØªØ³Øª ØªÙ†Ø¸ÛŒÙ…Ø§Øª</h3>
                <div style="font-size: 14px; line-height: 1.6;">
                    <strong>1. ØªØ³Øª Ù…ÛŒÚ©Ø±ÙˆÙÙ†:</strong> Ø¨Ø§Ù„Ø§ Ø±ÙˆÛŒ "ØªØ³Øª Ù…ÛŒÚ©Ø±ÙˆÙÙ†" Ú©Ù„ÛŒÚ© Ú©Ù†ÛŒØ¯<br>
                    <strong>2. Ú†Ú© Volume Meter:</strong> Ø¨Ø§ÛŒØ¯ ØµØ¯Ø§ Ø±Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ù‡Ø¯<br>
                    <strong>3. ØªØ³Øª Ø¨Ø§ Ù…ÙˆØ³ÛŒÙ‚ÛŒ:</strong> ÛŒÚ© Ø¢Ù‡Ù†Ú¯ Ù¾Ø®Ø´ Ú©Ù†ÛŒØ¯ Ùˆ Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ø¨Ø¨ÛŒÙ†ÛŒØ¯<br>
                    <strong>4. Browser Permission:</strong> Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ø±Ø§ Ø¨Ø¯Ù‡ÛŒØ¯
                </div>
            </div>
        </div>

        <!-- Speech Recognition Section -->
        <div class="section">
            <h2>ğŸ¯ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø± (Speech Recognition)</h2>
            <div class="controls">
                <button id="startBtn">Ø´Ø±ÙˆØ¹ Ø¶Ø¨Ø·</button>
                <button id="stopBtn" disabled>ØªÙˆÙ‚Ù Ø¶Ø¨Ø·</button>
                <select id="langSelect">
                    <option value="fa-IR">ÙØ§Ø±Ø³ÛŒ</option>
                    <option value="en-US">English</option>
                    <option value="ar-SA">Ø§Ù„Ø¹Ø±Ø¨ÙŠØ©</option>
                </select>
                <button id="testMicBtn">ØªØ³Øª Ù…ÛŒÚ©Ø±ÙˆÙÙ†</button>
            </div>
            <div id="status"></div>
            
            <!-- Volume meter -->
            <div style="margin: 15px 0;">
                <label>Ø³Ø·Ø­ ØµØ¯Ø§ÛŒ Ø¯Ø±ÛŒØ§ÙØªÛŒ:</label>
                <div id="volumeMeter" style="width: 100%; height: 20px; background: #f0f0f0; border-radius: 10px; overflow: hidden; margin-top: 5px;">
                    <div id="volumeBar" style="height: 100%; background: linear-gradient(90deg, #4caf50, #ffeb3b, #f44336); width: 0%; transition: width 0.1s;"></div>
                </div>
                <small id="volumeText">ØµØ¯Ø§ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯</small>
            </div>
            
            <textarea id="transcript" placeholder="Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§ÛŒÙ†Ø¬Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯..."></textarea>
        </div>

        <!-- Web Audio API Processing Section -->
        <div class="section">
            <h2>ğŸ§ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ø§ Web Audio API</h2>
            <div style="margin-bottom: 15px; padding: 12px; background: #d4edda; border-radius: 8px; border-left: 4px solid #28a745;">
                <strong>âœ… Ø±ÙˆØ´ Ù¾ÛŒØ´Ù†Ù‡Ø§Ø¯ÛŒ:</strong><br>
                â€¢ Ø§ÛŒÙ† Ø±ÙˆØ´ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ Ø±Ø§ Ù…ÛŒâ€ŒØ¯Ù‡Ø¯<br>
                â€¢ Ø¨Ø¯ÙˆÙ† Ù†ÛŒØ§Ø² Ø¨Ù‡ Ø¨Ø§Ø±Ú¯Ø°Ø§Ø±ÛŒ Ø§Ø¶Ø§ÙÛŒ<br>
                â€¢ Ø¨Ø§ Ù‡Ù…Ù‡ ÙØ±Ù…Øªâ€ŒÙ‡Ø§ÛŒ Ø±Ø§ÛŒØ¬ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯<br>
                â€¢ Ø³Ø±ÛŒØ¹ Ùˆ Ù‚Ø§Ø¨Ù„ Ø§Ø¹ØªÙ…Ø§Ø¯ Ø§Ø³Øª
            </div>
            
            <div class="controls">
                <input type="file" id="webAudioFile" accept="audio/*" style="margin-bottom: 10px;">
                <button id="processWebAudioBtn" disabled>Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ</button>
                <button id="stopWebAudioBtn" disabled>ØªÙˆÙ‚Ù</button>
            </div>
            
            <div id="webAudioStatus"></div>
            <div id="webAudioProgress" style="display: none; margin: 10px 0;">
                <div style="background: #f0f0f0; border-radius: 10px; overflow: hidden; height: 20px;">
                    <div id="webAudioProgressBar" style="height: 100%; background: linear-gradient(90deg, #ff9800, #f44336); width: 0%; transition: width 0.3s;"></div>
                </div>
                <small id="webAudioProgressText">0%</small>
            </div>
            
            <audio id="webAudioPlayer" controls style="width: 100%; margin: 10px 0; display: none;"></audio>
            <textarea id="webAudioTranscript" placeholder="Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø¨Ø§ Web Audio API Ø§ÛŒÙ†Ø¬Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯..."></textarea>
        </div>

        <!-- Audio File Processing Section -->
        <div class="section">
            <h2>ğŸµ ØªØ¨Ø¯ÛŒÙ„ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø¨Ù‡ Ù…ØªÙ† (Ø±ÙˆØ´ Ú©Ù„Ø§Ø³ÛŒÚ©)</h2>
            
            <!-- Settings Guide -->
            <div style="margin-bottom: 20px; padding: 15px; background: #e3f2fd; border-radius: 8px; border-left: 4px solid #2196f3;">
                <h3 style="margin-top: 0; color: #1976d2;">âš™ï¸ Ø±Ø§Ù‡Ù†Ù…Ø§ÛŒ ØªÙ†Ø¸ÛŒÙ…Ø§Øª Ø³ÛŒØ³ØªÙ…:</h3>
                <div style="font-size: 14px; line-height: 1.6;">
                    <strong>Windows:</strong><br>
                    â€¢ Ú©Ù†ØªØ±Ù„ Ù¾Ù†Ù„ â†’ Sound â†’ Recording â†’ Stereo Mix Ø±Ø§ ÙØ¹Ø§Ù„ Ú©Ù†ÛŒØ¯<br>
                    â€¢ ÛŒØ§: Settings â†’ System â†’ Sound â†’ Sound Control Panel â†’ Recording<br><br>
                    
                    <strong>Chrome:</strong><br>
                    â€¢ Ø¢Ø¯Ø±Ø³â€ŒØ¨Ø§Ø±: chrome://settings/content/microphone<br>
                    â€¢ Ø§Ø¬Ø§Ø²Ù‡ Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ø¨Ø±Ø§ÛŒ Ø§ÛŒÙ† Ø³Ø§ÛŒØª<br><br>
                    
                    <strong>Firefox:</strong><br>
                    â€¢ Ø¢ÛŒÚ©ÙˆÙ† Ù‚ÙÙ„ Ú©Ù†Ø§Ø± Ø¢Ø¯Ø±Ø³ â†’ Permissions â†’ Microphone<br><br>
                    
                    <strong>Ù†Ú©Ø§Øª Ù…Ù‡Ù…:</strong><br>
                    â€¢ ØµØ¯Ø§ÛŒ Ø³ÛŒØ³ØªÙ…: 70-80Ùª<br>
                    â€¢ Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ø­Ø³Ø§Ø³ÛŒØª: Ù…ØªÙˆØ³Ø·<br>
                    â€¢ Ù…Ø­ÛŒØ· Ø³Ø§Ú©Øª Ù†Ú¯Ù‡ Ø¯Ø§Ø±ÛŒØ¯
                </div>
            </div>
            
            <div class="controls">
                <input type="file" id="audioFile" accept="audio/*" style="margin-bottom: 10px;">
                <button id="processAudioBtn" disabled>Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ</button>
                <button id="stopProcessBtn" disabled>ØªÙˆÙ‚Ù Ù¾Ø±Ø¯Ø§Ø²Ø´</button>
            </div>
            <div id="audioStatus"></div>
            <audio id="audioPlayer" controls style="width: 100%; margin: 10px 0; display: none;"></audio>
            <textarea id="audioTranscript" placeholder="Ù…ØªÙ† ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ Ø§Ø² ÙØ§ÛŒÙ„ ØµÙˆØªÛŒ Ø§ÛŒÙ†Ø¬Ø§ Ù†Ù…Ø§ÛŒØ´ Ø¯Ø§Ø¯Ù‡ Ù…ÛŒâ€ŒØ´ÙˆØ¯..."></textarea>
            <div style="margin-top: 10px; padding: 10px; background: #fff3cd; border-radius: 5px; font-size: 14px;">
                âš ï¸ <strong>Ù†Ú©ØªÙ‡:</strong> Ø§ÛŒÙ† Ø±ÙˆØ´ Ø§Ø² Ø·Ø±ÛŒÙ‚ Ù¾Ø®Ø´ ÙØ§ÛŒÙ„ Ùˆ Ø¶Ø¨Ø· Ù…Ø¬Ø¯Ø¯ Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯. Ø¨Ø±Ø§ÛŒ Ø¨Ù‡ØªØ±ÛŒÙ† Ù†ØªÛŒØ¬Ù‡ ØµØ¯Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø±Ø§ Ø¨Ø§Ù„Ø§ Ø¨Ø¨Ø±ÛŒØ¯ Ùˆ Ø³Ø±ÙˆØµØ¯Ø§ÛŒ Ù…Ø­ÛŒØ· Ø±Ø§ Ú©Ù… Ú©Ù†ÛŒØ¯.
            </div>
        </div>
        
        <!-- Speech Synthesis Section -->
        <div class="section">
            <h2>ğŸ”Š ØªÙˆÙ„ÛŒØ¯ Ú¯ÙØªØ§Ø± (Speech Synthesis)</h2>
            <textarea id="textToSpeak" placeholder="Ù…ØªÙ†ÛŒ Ú©Ù‡ Ù…ÛŒâ€ŒØ®ÙˆØ§Ù‡ÛŒØ¯ Ø¨Ø®ÙˆØ§Ù†ÛŒØ¯ Ø±Ø§ Ø§ÛŒÙ†Ø¬Ø§ Ø¨Ù†ÙˆÛŒØ³ÛŒØ¯...">Ø³Ù„Ø§Ù…! Ø§ÛŒÙ† ÛŒÚ© ØªØ³Øª Ø¨Ø±Ø§ÛŒ Web Speech API Ø§Ø³Øª.</textarea>
            <div class="controls">
                <button id="speakBtn">Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ†</button>
                <button id="pauseBtn">ØªÙˆÙ‚Ù</button>
                <select id="voiceSelect"></select>
                <label>Ø³Ø±Ø¹Øª: <input type="range" id="rateSlider" min="0.5" max="2" step="0.1" value="1"></label>
                <label>Ø¨Ù„Ù†Ø¯ÛŒ: <input type="range" id="volumeSlider" min="0" max="1" step="0.1" value="1"></label>
            </div>
        </div>

        <!-- Footer -->
        <div class="footer">
            <p>Ø³Ø§Ø®ØªÙ‡ Ø´Ø¯Ù‡ Ø¨Ø§ <span class="heart">â¤ï¸</span> Ø¨Ù‡ Ú©Ù…Ú© Claude 4</p>
            <p>ØªÙˆØ³Ø¹Ù‡ Ø¯Ø§Ø¯Ù‡ Ø´Ø¯Ù‡ ØªÙˆØ³Ø· <a href="https://x.com/NabiKAZ" target="_blank">NabiKAZ</a></p>
            <a href="https://github.com/NabiKAZ/Web-Speech-API" target="_blank" class="github-icon" title="Ù…Ø´Ø§Ù‡Ø¯Ù‡ Ø¯Ø± Ú¯ÛŒØªÙ‡Ø§Ø¨">
                <svg viewBox="0 0 24 24" fill="currentColor">
                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                </svg>
            </a>
        </div>
    </div>

    <script>
        // Speech Recognition
        let recognition;
        let audioRecognition;
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcript = document.getElementById('transcript');
        const status = document.getElementById('status');
        const langSelect = document.getElementById('langSelect');
        const testMicBtn = document.getElementById('testMicBtn');
        const volumeMeter = document.getElementById('volumeMeter');
        const volumeBar = document.getElementById('volumeBar');
        const volumeText = document.getElementById('volumeText');

        // Audio File Processing
        const audioFile = document.getElementById('audioFile');
        const processAudioBtn = document.getElementById('processAudioBtn');
        const stopProcessBtn = document.getElementById('stopProcessBtn');
        const audioPlayer = document.getElementById('audioPlayer');
        const audioTranscript = document.getElementById('audioTranscript');
        const audioStatus = document.getElementById('audioStatus');

        // Web Audio API variables
        const webAudioFile = document.getElementById('webAudioFile');
        const processWebAudioBtn = document.getElementById('processWebAudioBtn');
        const stopWebAudioBtn = document.getElementById('stopWebAudioBtn');
        const webAudioStatus = document.getElementById('webAudioStatus');
        const webAudioProgress = document.getElementById('webAudioProgress');
        const webAudioProgressBar = document.getElementById('webAudioProgressBar');
        const webAudioProgressText = document.getElementById('webAudioProgressText');
        const webAudioPlayer = document.getElementById('webAudioPlayer');
        const webAudioTranscript = document.getElementById('webAudioTranscript');

        let audioContext;
        let analyser;
        let microphone;
        let animationId;

        // Check browser support
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'fa-IR';
            
            recognition.onstart = () => {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.classList.add('recording');
                status.innerHTML = '<div class="status listening">ğŸ¤ Ø¯Ø± Ø­Ø§Ù„ Ú¯ÙˆØ´ Ø¯Ø§Ø¯Ù†...</div>';
            };
            
            recognition.onresult = (event) => {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcriptPart = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcriptPart;
                    } else {
                        interimTranscript += transcriptPart;
                    }
                }
                
                transcript.value = finalTranscript + interimTranscript;
            };
            
            recognition.onerror = (event) => {
                status.innerHTML = `<div class="status error">âŒ Ø®Ø·Ø§: ${event.error}</div>`;
                resetButtons();
            };
            
            recognition.onend = () => {
                status.innerHTML = '<div class="status">âœ… Ø¶Ø¨Ø· Ù…ØªÙˆÙ‚Ù Ø´Ø¯</div>';
                resetButtons();
            };
            
            startBtn.onclick = () => {
                recognition.lang = langSelect.value;
                recognition.start();
            };
            
            stopBtn.onclick = () => {
                recognition.stop();
            };
            
        } else {
            status.innerHTML = '<div class="status error">âŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ø´Ù…Ø§ Ø§Ø² Speech Recognition Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯</div>';
            startBtn.disabled = true;
        }

        function resetButtons() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
            startBtn.classList.remove('recording');
        }

        // Test microphone function
        testMicBtn.onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 256;
                microphone.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                function updateVolume() {
                    analyser.getByteFrequencyData(dataArray);
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const percentage = (average / 255) * 100;
                    
                    volumeBar.style.width = percentage + '%';
                    volumeText.textContent = `Ø³Ø·Ø­ ØµØ¯Ø§: ${Math.round(percentage)}%`;
                    
                    if (percentage > 5) {
                        status.innerHTML = '<div class="status listening">âœ… Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ú©Ø§Ø± Ù…ÛŒâ€ŒÚ©Ù†Ø¯!</div>';
                    }
                    
                    animationId = requestAnimationFrame(updateVolume);
                }
                
                updateVolume();
                status.innerHTML = '<div class="status listening">ğŸ¤ ØªØ³Øª Ù…ÛŒÚ©Ø±ÙˆÙÙ†... ØµØ­Ø¨Øª Ú©Ù†ÛŒØ¯</div>';
                
                // Stop test after 10 seconds
                setTimeout(() => {
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                    stream.getTracks().forEach(track => track.stop());
                    volumeBar.style.width = '0%';
                    volumeText.textContent = 'ØªØ³Øª ØªÙ…Ø§Ù… Ø´Ø¯';
                }, 10000);
                
            } catch (error) {
                status.innerHTML = '<div class="status error">âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ†: ' + error.message + '</div>';
            }
        };

        // Audio File Processing Functions
        audioFile.onchange = (event) => {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioPlayer.src = url;
                audioPlayer.style.display = 'block';
                processAudioBtn.disabled = false;
                audioStatus.innerHTML = '<div class="status">ğŸ“ ÙØ§ÛŒÙ„ Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø§Ø³Øª</div>';
            }
        };

        processAudioBtn.onclick = async () => {
            if (!audioFile.files[0]) return;
            
            try {
                // Check microphone first
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop()); // Stop the test stream
                
                // Setup audio recognition
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    audioRecognition = new SpeechRecognition();
                    
                    audioRecognition.continuous = true;
                    audioRecognition.interimResults = true;
                    audioRecognition.lang = langSelect.value;
                    audioRecognition.maxAlternatives = 1;
                    
                    let finalTranscript = '';
                    
                    audioRecognition.onstart = () => {
                        processAudioBtn.disabled = true;
                        stopProcessBtn.disabled = false;
                        audioStatus.innerHTML = '<div class="status listening">ğŸ¤ Ø¢Ù…Ø§Ø¯Ù‡â€ŒØ³Ø§Ø²ÛŒ Ù¾Ø±Ø¯Ø§Ø²Ø´...</div>';
                        audioTranscript.value = '';
                        
                        // Start playing audio after recognition starts
                        setTimeout(() => {
                            audioPlayer.currentTime = 0;
                            audioPlayer.volume = 0.8; // Set volume to 80%
                            audioPlayer.play();
                            audioStatus.innerHTML = '<div class="status listening">ğŸµ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø®Ø´ Ùˆ Ù¾Ø±Ø¯Ø§Ø²Ø´ ÙØ§ÛŒÙ„...</div>';
                        }, 1500);
                    };
                    
                    audioRecognition.onresult = (event) => {
                        let interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const transcriptPart = event.results[i][0].transcript;
                            if (event.results[i].isFinal) {
                                finalTranscript += transcriptPart + ' ';
                            } else {
                                interimTranscript += transcriptPart;
                            }
                        }
                        
                        audioTranscript.value = finalTranscript + interimTranscript;
                        
                        // Show progress
                        const currentTime = audioPlayer.currentTime;
                        const duration = audioPlayer.duration;
                        const progress = duration ? Math.round((currentTime / duration) * 100) : 0;
                        audioStatus.innerHTML = `<div class="status listening">ğŸµ Ù¾Ø±Ø¯Ø§Ø²Ø´: ${progress}% (${Math.round(currentTime)}s / ${Math.round(duration)}s)</div>`;
                    };
                    
                    audioRecognition.onerror = (event) => {
                        let errorMsg = 'Ø®Ø·Ø§ÛŒ Ù†Ø§Ù…Ø´Ø®Øµ';
                        switch(event.error) {
                            case 'no-speech':
                                errorMsg = 'ØµØ¯Ø§ÛŒÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯ - ØµØ¯Ø§ÛŒ Ø³ÛŒØ³ØªÙ… Ø±Ø§ Ø¨Ø§Ù„Ø§ Ø¨Ø¨Ø±ÛŒØ¯';
                                break;
                            case 'audio-capture':
                                errorMsg = 'Ù…Ø´Ú©Ù„ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ†';
                                break;
                            case 'not-allowed':
                                errorMsg = 'Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ† Ù…Ø¬Ø§Ø² Ù†ÛŒØ³Øª';
                                break;
                            case 'network':
                                errorMsg = 'Ù…Ø´Ú©Ù„ Ø§ØªØµØ§Ù„ Ø´Ø¨Ú©Ù‡';
                                break;
                            default:
                                errorMsg = event.error;
                        }
                        audioStatus.innerHTML = `<div class="status error">âŒ ${errorMsg}</div>`;
                        resetAudioButtons();
                    };
                    
                    audioRecognition.onend = () => {
                        if (finalTranscript.trim()) {
                            audioStatus.innerHTML = '<div class="status">âœ… Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Ù…ÙˆÙÙ‚ÛŒØª ØªÙ…Ø§Ù… Ø´Ø¯</div>';
                        } else {
                            audioStatus.innerHTML = '<div class="status error">âš ï¸ Ù…ØªÙ†ÛŒ ØªØ´Ø®ÛŒØµ Ø¯Ø§Ø¯Ù‡ Ù†Ø´Ø¯ - ØªÙ†Ø¸ÛŒÙ…Ø§Øª ØµØ¯Ø§ Ø±Ø§ Ø¨Ø±Ø±Ø³ÛŒ Ú©Ù†ÛŒØ¯</div>';
                        }
                        resetAudioButtons();
                        audioPlayer.pause();
                    };
                    
                    // Start recognition
                    audioRecognition.start();
                    
                    // Stop recognition when audio ends
                    audioPlayer.onended = () => {
                        setTimeout(() => {
                            if (audioRecognition) {
                                audioRecognition.stop();
                            }
                        }, 3000); // Wait 3 seconds after audio ends
                    };
                    
                } else {
                    audioStatus.innerHTML = '<div class="status error">âŒ Ù…Ø±ÙˆØ±Ú¯Ø± Ø§Ø² Speech Recognition Ù¾Ø´ØªÛŒØ¨Ø§Ù†ÛŒ Ù†Ù…ÛŒâ€ŒÚ©Ù†Ø¯</div>';
                }
                
            } catch (error) {
                audioStatus.innerHTML = `<div class="status error">âŒ Ø®Ø·Ø§ Ø¯Ø± Ø¯Ø³ØªØ±Ø³ÛŒ Ø¨Ù‡ Ù…ÛŒÚ©Ø±ÙˆÙÙ†: ${error.message}</div>`;
                resetAudioButtons();
            }
        };

        stopProcessBtn.onclick = () => {
            if (audioRecognition) {
                audioRecognition.stop();
            }
            audioPlayer.pause();
            resetAudioButtons();
        };

        function resetAudioButtons() {
            processAudioBtn.disabled = false;
            stopProcessBtn.disabled = true;
        }

        // Web Audio API Functions
        webAudioFile.onchange = (event) => {
            const file = event.target.files[0];
            if (file) {
                webAudioStatus.innerHTML = '<div class="status">ğŸ“ ÙØ§ÛŒÙ„ Ø¢Ù…Ø§Ø¯Ù‡ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Web Audio API</div>';
                processWebAudioBtn.disabled = false;
            }
        };

        processWebAudioBtn.onclick = async () => {
            const file = webAudioFile.files[0];
            if (!file) return;
            
            try {
                processWebAudioBtn.disabled = true;
                stopWebAudioBtn.disabled = false;
                webAudioProgress.style.display = 'block';
                webAudioStatus.innerHTML = '<div class="status listening">ğŸ§ Ø¯Ø± Ø­Ø§Ù„ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Web Audio API...</div>';
                
                // Create audio context
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Read file as ArrayBuffer
                const arrayBuffer = await file.arrayBuffer();
                webAudioProgressBar.style.width = '25%';
                webAudioProgressText.textContent = 'Ø®ÙˆØ§Ù†Ø¯Ù† ÙØ§ÛŒÙ„: 25%';
                
                // Decode audio data
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                webAudioProgressBar.style.width = '50%';
                webAudioProgressText.textContent = 'Ù¾Ø±Ø¯Ø§Ø²Ø´ ØµÙˆØª: 50%';
                
                // Convert to WAV blob
                const wavBlob = await audioBufferToWav(audioBuffer);
                const audioUrl = URL.createObjectURL(wavBlob);
                
                webAudioProgressBar.style.width = '75%';
                webAudioProgressText.textContent = 'ØªØ¨Ø¯ÛŒÙ„ ÙØ±Ù…Øª: 75%';
                
                // Setup audio player
                webAudioPlayer.src = audioUrl;
                webAudioPlayer.style.display = 'block';
                
                webAudioProgressBar.style.width = '100%';
                webAudioProgressText.textContent = 'Ø¢Ù…Ø§Ø¯Ù‡ ØªØ´Ø®ÛŒØµ: 100%';
                
                // Process with speech recognition
                await processWithWebAudio(audioUrl);
                
                webAudioProgress.style.display = 'none';
                
            } catch (error) {
                webAudioStatus.innerHTML = `<div class="status error">âŒ Ø®Ø·Ø§ Ø¯Ø± Ù¾Ø±Ø¯Ø§Ø²Ø´: ${error.message}</div>`;
                webAudioProgress.style.display = 'none';
                resetWebAudioButtons();
            }
        };

        async function audioBufferToWav(buffer) {
            const length = buffer.length;
            const sampleRate = buffer.sampleRate;
            const numberOfChannels = buffer.numberOfChannels;
            
            // Convert to mono
            const monoBuffer = new Float32Array(length);
            if (numberOfChannels === 1) {
                monoBuffer.set(buffer.getChannelData(0));
            } else {
                const leftChannel = buffer.getChannelData(0);
                const rightChannel = buffer.getChannelData(1);
                for (let i = 0; i < length; i++) {
                    monoBuffer[i] = (leftChannel[i] + rightChannel[i]) / 2;
                }
            }
            
            // Create WAV file
            const wavBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(wavBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, monoBuffer[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return new Blob([wavBuffer], { type: 'audio/wav' });
        }

        async function processWithWebAudio(audioUrl) {
            return new Promise((resolve, reject) => {
                try {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    const recognition = new SpeechRecognition();
                    
                    recognition.continuous = true;
                    recognition.interimResults = true;
                    recognition.lang = langSelect.value;
                    recognition.maxAlternatives = 3;
                    
                    let finalTranscript = '';
                    const audio = new Audio(audioUrl);
                    
                    recognition.onstart = () => {
                        webAudioStatus.innerHTML = '<div class="status listening">ğŸ¤ Ø´Ø±ÙˆØ¹ ØªØ´Ø®ÛŒØµ Ú¯ÙØªØ§Ø±...</div>';
                        setTimeout(() => {
                            audio.volume = 1.0;
                            audio.play();
                        }, 1000);
                    };
                    
                    recognition.onresult = (event) => {
                        let interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const result = event.results[i];
                            const transcriptPart = result[0].transcript;
                            
                            if (result.isFinal) {
                                finalTranscript += transcriptPart + ' ';
                            } else {
                                interimTranscript += transcriptPart;
                            }
                        }
                        
                        webAudioTranscript.value = finalTranscript + interimTranscript;
                        
                        // Show progress
                        const progress = audio.duration ? Math.round((audio.currentTime / audio.duration) * 100) : 0;
                        webAudioStatus.innerHTML = `<div class="status listening">ğŸµ Ù¾Ø±Ø¯Ø§Ø²Ø´: ${progress}% - ${Math.round(audio.currentTime)}s</div>`;
                    };
                    
                    recognition.onerror = (event) => {
                        webAudioStatus.innerHTML = `<div class="status error">âŒ Ø®Ø·Ø§: ${event.error}</div>`;
                        reject(event.error);
                    };
                    
                    recognition.onend = () => {
                        if (finalTranscript.trim()) {
                            webAudioStatus.innerHTML = '<div class="status">ğŸ‰ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ø¨Ø§ Web Audio API Ú©Ø§Ù…Ù„ Ø´Ø¯!</div>';
                        } else {
                            webAudioStatus.innerHTML = '<div class="status error">âš ï¸ Ù…ØªÙ†ÛŒ ØªØ´Ø®ÛŒØµ Ù†Ø´Ø¯</div>';
                        }
                        resetWebAudioButtons();
                        resolve();
                    };
                    
                    audio.onended = () => {
                        setTimeout(() => recognition.stop(), 3000);
                    };
                    
                    recognition.start();
                    
                } catch (error) {
                    reject(error);
                }
            });
        }

        stopWebAudioBtn.onclick = () => {
            webAudioStatus.innerHTML = '<div class="status">â¹ï¸ Ù¾Ø±Ø¯Ø§Ø²Ø´ Ù…ØªÙˆÙ‚Ù Ø´Ø¯</div>';
            resetWebAudioButtons();
        };

        function resetWebAudioButtons() {
            processWebAudioBtn.disabled = false;
            stopWebAudioBtn.disabled = true;
        }

        // Speech Synthesis
        const textToSpeak = document.getElementById('textToSpeak');
        const speakBtn = document.getElementById('speakBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const voiceSelect = document.getElementById('voiceSelect');
        const rateSlider = document.getElementById('rateSlider');
        const volumeSlider = document.getElementById('volumeSlider');

        let voices = [];
        let currentUtterance = null;

        function loadVoices() {
            voices = speechSynthesis.getVoices();
            voiceSelect.innerHTML = '';
            
            voices.forEach((voice, index) => {
                const option = document.createElement('option');
                option.value = index;
                option.textContent = `${voice.name} (${voice.lang})`;
                if (voice.lang.includes('fa') || voice.lang.includes('FA')) {
                    option.selected = true;
                }
                voiceSelect.appendChild(option);
            });
        }

        // Load voices when available
        speechSynthesis.onvoiceschanged = loadVoices;
        loadVoices();

        speakBtn.onclick = () => {
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }
            
            const text = textToSpeak.value.trim();
            if (!text) return;
            
            currentUtterance = new SpeechSynthesisUtterance(text);
            currentUtterance.voice = voices[voiceSelect.value];
            currentUtterance.rate = parseFloat(rateSlider.value);
            currentUtterance.volume = parseFloat(volumeSlider.value);
            
            currentUtterance.onstart = () => {
                speakBtn.textContent = 'ğŸ”Š Ø¯Ø± Ø­Ø§Ù„ Ø®ÙˆØ§Ù†Ø¯Ù†...';
                speakBtn.disabled = true;
            };
            
            currentUtterance.onend = () => {
                speakBtn.textContent = 'Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ†';
                speakBtn.disabled = false;
            };
            
            currentUtterance.onerror = () => {
                speakBtn.textContent = 'Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ†';
                speakBtn.disabled = false;
            };
            
            speechSynthesis.speak(currentUtterance);
        };

        pauseBtn.onclick = () => {
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
                speakBtn.textContent = 'Ø®ÙˆØ§Ù†Ø¯Ù† Ù…ØªÙ†';
                speakBtn.disabled = false;
            }
        };

        // Update sliders display
        rateSlider.oninput = () => {
            rateSlider.nextElementSibling.textContent = rateSlider.value;
        };
        
        volumeSlider.oninput = () => {
            volumeSlider.nextElementSibling.textContent = volumeSlider.value;
        };
    </script>
</body>
</html>