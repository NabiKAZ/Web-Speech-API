<!DOCTYPE html>
<html lang="fa" dir="rtl">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Web Speech API Demo</title>
    <style>
        body {
            font-family: 'Segoe UI', Tahoma, Geneva, Verdana, sans-serif;
            max-width: 800px;
            margin: 0 auto;
            padding: 20px;
            background: linear-gradient(135deg, #667eea 0%, #764ba2 100%);
            min-height: 100vh;
            color: #333;
        }
        
        .container {
            background: white;
            border-radius: 15px;
            padding: 30px;
            box-shadow: 0 10px 30px rgba(0,0,0,0.2);
        }
        
        h1 {
            text-align: center;
            color: #4a5568;
            margin-bottom: 30px;
        }
        
        .section {
            margin-bottom: 30px;
            padding: 20px;
            border: 2px solid #e2e8f0;
            border-radius: 10px;
            background: #f8fafc;
        }
        
        button {
            background: linear-gradient(45deg, #667eea, #764ba2);
            color: white;
            border: none;
            padding: 12px 24px;
            border-radius: 8px;
            cursor: pointer;
            font-size: 16px;
            margin: 5px;
            transition: all 0.3s ease;
        }
        
        button:hover {
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        button:disabled {
            background: #cbd5e0;
            cursor: not-allowed;
            transform: none;
        }
        
        textarea {
            width: 100%;
            min-height: 100px;
            padding: 15px;
            border: 2px solid #e2e8f0;
            border-radius: 8px;
            font-size: 16px;
            font-family: inherit;
            resize: vertical;
        }
        
        .status {
            padding: 10px;
            margin: 10px 0;
            border-radius: 5px;
            font-weight: bold;
        }
        
        .listening {
            background: #d4edda;
            color: #155724;
            border: 1px solid #c3e6cb;
        }
        
        .error {
            background: #f8d7da;
            color: #721c24;
            border: 1px solid #f5c6cb;
        }
        
        .controls {
            display: flex;
            gap: 10px;
            align-items: center;
            flex-wrap: wrap;
        }
        
        select {
            padding: 8px 12px;
            border: 2px solid #e2e8f0;
            border-radius: 5px;
            font-size: 14px;
        }
        
        .recording {
            animation: pulse 1s infinite;
        }
        
        @keyframes pulse {
            0% { opacity: 1; }
            50% { opacity: 0.5; }
            100% { opacity: 1; }
        }
        
        .footer {
            text-align: center;
            margin-top: 40px;
            padding: 20px;
            border-top: 2px solid #e2e8f0;
            color: #666;
            font-size: 14px;
        }
        
        .footer .heart {
            color: #e53e3e;
            animation: heartbeat 1.5s ease-in-out infinite;
        }
        
        .footer .github-icon {
            display: inline-flex;
            align-items: center;
            justify-content: center;
            width: 32px;
            height: 32px;
            margin: 10px auto 0;
            background: #333;
            border-radius: 50%;
            color: white;
            text-decoration: none;
            transition: all 0.3s ease;
        }
        
        .footer .github-icon:hover {
            background: #667eea;
            transform: translateY(-2px);
            box-shadow: 0 5px 15px rgba(0,0,0,0.2);
        }
        
        .footer .github-icon svg {
            width: 18px;
            height: 18px;
        }
        
        @keyframes heartbeat {
            0%, 100% { transform: scale(1); }
            50% { transform: scale(1.1); }
        }
    </style>
</head>
<body>
    <div class="container">
        <h1>🎤 Web Speech API Demo</h1>
        
        <!-- Windows Virtual Audio Setup Guide -->
        <div class="section" style="background: #f8f9fa; border: 2px solid #dee2e6;">
            <h2>🖥️ راهنمای تنظیمات Windows</h2>
            
            <div style="margin-bottom: 20px; padding: 15px; background: #e7f3ff; border-radius: 8px; border-left: 4px solid #0066cc;">
                <h3 style="margin-top: 0; color: #0066cc;">🔧 روش 1: فعال‌سازی Stereo Mix (رایگان)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># باز کردن Sound Settings</div>
                    Win + R → mmsys.cpl → Enter<br><br>
                    
                    <div style="color: #98c379;"># فعال‌سازی Stereo Mix</div>
                    1. تب "Recording" → Right Click → "Show Disabled Devices"<br>
                    2. "Stereo Mix" → Right Click → "Enable"<br>
                    3. "Stereo Mix" → Right Click → "Set as Default Device"<br><br>
                    
                    <div style="color: #98c379;"># تنظیم Volume</div>
                    4. "Stereo Mix" → Double Click → Levels → 70-80%<br>
                    5. Advanced → 16 bit, 44100 Hz → OK
                </div>
            </div>

            <div style="margin-bottom: 20px; padding: 15px; background: #fff3cd; border-radius: 8px; border-left: 4px solid #ffc107;">
                <h3 style="margin-top: 0; color: #856404;">🛠️ روش 2: VB-Audio Virtual Cable (پیشنهادی)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># دانلود و نصب</div>
                    1. Download: https://vb-audio.com/Cable/<br>
                    2. Extract → Run as Administrator → Install<br>
                    3. Restart Windows<br><br>
                    
                    <div style="color: #98c379;"># تنظیمات</div>
                    4. Sound Settings → Output → "CABLE Input"<br>
                    5. Sound Settings → Input → "CABLE Output"<br>
                    6. Volume: 80-90%
                </div>
            </div>

            <div style="margin-bottom: 20px; padding: 15px; background: #d1ecf1; border-radius: 8px; border-left: 4px solid #17a2b8;">
                <h3 style="margin-top: 0; color: #0c5460;">🎵 روش 3: VoiceMeeter (حرفه‌ای)</h3>
                <div style="font-family: 'Courier New', monospace; background: #1e1e1e; color: #ffffff; padding: 15px; border-radius: 8px; margin: 10px 0; font-size: 14px;">
                    <div style="color: #98c379;"># نصب VoiceMeeter</div>
                    1. Download: https://vb-audio.com/Voicemeeter/<br>
                    2. Install → Restart<br><br>
                    
                    <div style="color: #98c379;"># تنظیمات</div>
                    3. Windows Sound → Output → "VoiceMeeter Input"<br>
                    4. Windows Sound → Input → "VoiceMeeter Output"<br>
                    5. VoiceMeeter → A1: Default speakers<br>
                    6. B1: Enable for routing
                </div>
            </div>

            <div style="padding: 15px; background: #d4edda; border-radius: 8px; border-left: 4px solid #28a745;">
                <h3 style="margin-top: 0; color: #155724;">✅ تست تنظیمات</h3>
                <div style="font-size: 14px; line-height: 1.6;">
                    <strong>1. تست میکروفن:</strong> بالا روی "تست میکروفن" کلیک کنید<br>
                    <strong>2. چک Volume Meter:</strong> باید صدا را تشخیص دهد<br>
                    <strong>3. تست با موسیقی:</strong> یک آهنگ پخش کنید و نتیجه را ببینید<br>
                    <strong>4. Browser Permission:</strong> اجازه دسترسی به میکروفن را بدهید
                </div>
            </div>
        </div>

        <!-- Speech Recognition Section -->
        <div class="section">
            <h2>🎯 تشخیص گفتار (Speech Recognition)</h2>
            <div class="controls">
                <button id="startBtn">شروع ضبط</button>
                <button id="stopBtn" disabled>توقف ضبط</button>
                <select id="langSelect">
                    <option value="fa-IR">فارسی</option>
                    <option value="en-US">English</option>
                    <option value="ar-SA">العربية</option>
                </select>
                <button id="testMicBtn">تست میکروفن</button>
            </div>
            <div id="status"></div>
            
            <!-- Volume meter -->
            <div style="margin: 15px 0;">
                <label>سطح صدای دریافتی:</label>
                <div id="volumeMeter" style="width: 100%; height: 20px; background: #f0f0f0; border-radius: 10px; overflow: hidden; margin-top: 5px;">
                    <div id="volumeBar" style="height: 100%; background: linear-gradient(90deg, #4caf50, #ffeb3b, #f44336); width: 0%; transition: width 0.1s;"></div>
                </div>
                <small id="volumeText">صدا تشخیص داده نشد</small>
            </div>
            
            <textarea id="transcript" placeholder="متن تشخیص داده شده اینجا نمایش داده می‌شود..."></textarea>
        </div>

        <!-- Web Audio API Processing Section -->
        <div class="section">
            <h2>🎧 پردازش فایل صوتی با Web Audio API</h2>
            <div style="margin-bottom: 15px; padding: 12px; background: #d4edda; border-radius: 8px; border-left: 4px solid #28a745;">
                <strong>✅ روش پیشنهادی:</strong><br>
                • این روش بهترین نتیجه را می‌دهد<br>
                • بدون نیاز به بارگذاری اضافی<br>
                • با همه فرمت‌های رایج کار می‌کند<br>
                • سریع و قابل اعتماد است
            </div>
            
            <div class="controls">
                <input type="file" id="webAudioFile" accept="audio/*" style="margin-bottom: 10px;">
                <button id="processWebAudioBtn" disabled>پردازش فایل صوتی</button>
                <button id="stopWebAudioBtn" disabled>توقف</button>
            </div>
            
            <div id="webAudioStatus"></div>
            <div id="webAudioProgress" style="display: none; margin: 10px 0;">
                <div style="background: #f0f0f0; border-radius: 10px; overflow: hidden; height: 20px;">
                    <div id="webAudioProgressBar" style="height: 100%; background: linear-gradient(90deg, #ff9800, #f44336); width: 0%; transition: width 0.3s;"></div>
                </div>
                <small id="webAudioProgressText">0%</small>
            </div>
            
            <audio id="webAudioPlayer" controls style="width: 100%; margin: 10px 0; display: none;"></audio>
            <textarea id="webAudioTranscript" placeholder="متن تشخیص داده شده با Web Audio API اینجا نمایش داده می‌شود..."></textarea>
        </div>

        <!-- Audio File Processing Section -->
        <div class="section">
            <h2>🎵 تبدیل فایل صوتی به متن (روش کلاسیک)</h2>
            
            <!-- Settings Guide -->
            <div style="margin-bottom: 20px; padding: 15px; background: #e3f2fd; border-radius: 8px; border-left: 4px solid #2196f3;">
                <h3 style="margin-top: 0; color: #1976d2;">⚙️ راهنمای تنظیمات سیستم:</h3>
                <div style="font-size: 14px; line-height: 1.6;">
                    <strong>Windows:</strong><br>
                    • کنترل پنل → Sound → Recording → Stereo Mix را فعال کنید<br>
                    • یا: Settings → System → Sound → Sound Control Panel → Recording<br><br>
                    
                    <strong>Chrome:</strong><br>
                    • آدرس‌بار: chrome://settings/content/microphone<br>
                    • اجازه دسترسی به میکروفن برای این سایت<br><br>
                    
                    <strong>Firefox:</strong><br>
                    • آیکون قفل کنار آدرس → Permissions → Microphone<br><br>
                    
                    <strong>نکات مهم:</strong><br>
                    • صدای سیستم: 70-80٪<br>
                    • میکروفن حساسیت: متوسط<br>
                    • محیط ساکت نگه دارید
                </div>
            </div>
            
            <div class="controls">
                <input type="file" id="audioFile" accept="audio/*" style="margin-bottom: 10px;">
                <button id="processAudioBtn" disabled>پردازش فایل صوتی</button>
                <button id="stopProcessBtn" disabled>توقف پردازش</button>
            </div>
            <div id="audioStatus"></div>
            <audio id="audioPlayer" controls style="width: 100%; margin: 10px 0; display: none;"></audio>
            <textarea id="audioTranscript" placeholder="متن تشخیص داده شده از فایل صوتی اینجا نمایش داده می‌شود..."></textarea>
            <div style="margin-top: 10px; padding: 10px; background: #fff3cd; border-radius: 5px; font-size: 14px;">
                ⚠️ <strong>نکته:</strong> این روش از طریق پخش فایل و ضبط مجدد کار می‌کند. برای بهترین نتیجه صدای سیستم را بالا ببرید و سروصدای محیط را کم کنید.
            </div>
        </div>
        
        <!-- Speech Synthesis Section -->
        <div class="section">
            <h2>🔊 تولید گفتار (Speech Synthesis)</h2>
            <textarea id="textToSpeak" placeholder="متنی که می‌خواهید بخوانید را اینجا بنویسید...">سلام! این یک تست برای Web Speech API است.</textarea>
            <div class="controls">
                <button id="speakBtn">خواندن متن</button>
                <button id="pauseBtn">توقف</button>
                <select id="voiceSelect"></select>
                <label>سرعت: <input type="range" id="rateSlider" min="0.5" max="2" step="0.1" value="1"></label>
                <label>بلندی: <input type="range" id="volumeSlider" min="0" max="1" step="0.1" value="1"></label>
            </div>
        </div>

        <!-- Footer -->
        <div class="footer">
            <p>ساخته شده با <span class="heart">❤️</span> به کمک Claude 4</p>
            <p>توسعه داده شده توسط <a href="https://x.com/NabiKAZ" target="_blank">NabiKAZ</a></p>
            <a href="https://github.com/NabiKAZ/Web-Speech-API" target="_blank" class="github-icon" title="مشاهده در گیتهاب">
                <svg viewBox="0 0 24 24" fill="currentColor">
                    <path d="M12 0c-6.626 0-12 5.373-12 12 0 5.302 3.438 9.8 8.207 11.387.599.111.793-.261.793-.577v-2.234c-3.338.726-4.033-1.416-4.033-1.416-.546-1.387-1.333-1.756-1.333-1.756-1.089-.745.083-.729.083-.729 1.205.084 1.839 1.237 1.839 1.237 1.07 1.834 2.807 1.304 3.492.997.107-.775.418-1.305.762-1.604-2.665-.305-5.467-1.334-5.467-5.931 0-1.311.469-2.381 1.236-3.221-.124-.303-.535-1.524.117-3.176 0 0 1.008-.322 3.301 1.23.957-.266 1.983-.399 3.003-.404 1.02.005 2.047.138 3.006.404 2.291-1.552 3.297-1.23 3.297-1.23.653 1.653.242 2.874.118 3.176.77.84 1.235 1.911 1.235 3.221 0 4.609-2.807 5.624-5.479 5.921.43.372.823 1.102.823 2.222v3.293c0 .319.192.694.801.576 4.765-1.589 8.199-6.086 8.199-11.386 0-6.627-5.373-12-12-12z"/>
                </svg>
            </a>
        </div>
    </div>

    <script>
        // Speech Recognition
        let recognition;
        let audioRecognition;
        const startBtn = document.getElementById('startBtn');
        const stopBtn = document.getElementById('stopBtn');
        const transcript = document.getElementById('transcript');
        const status = document.getElementById('status');
        const langSelect = document.getElementById('langSelect');
        const testMicBtn = document.getElementById('testMicBtn');
        const volumeMeter = document.getElementById('volumeMeter');
        const volumeBar = document.getElementById('volumeBar');
        const volumeText = document.getElementById('volumeText');

        // Audio File Processing
        const audioFile = document.getElementById('audioFile');
        const processAudioBtn = document.getElementById('processAudioBtn');
        const stopProcessBtn = document.getElementById('stopProcessBtn');
        const audioPlayer = document.getElementById('audioPlayer');
        const audioTranscript = document.getElementById('audioTranscript');
        const audioStatus = document.getElementById('audioStatus');

        // Web Audio API variables
        const webAudioFile = document.getElementById('webAudioFile');
        const processWebAudioBtn = document.getElementById('processWebAudioBtn');
        const stopWebAudioBtn = document.getElementById('stopWebAudioBtn');
        const webAudioStatus = document.getElementById('webAudioStatus');
        const webAudioProgress = document.getElementById('webAudioProgress');
        const webAudioProgressBar = document.getElementById('webAudioProgressBar');
        const webAudioProgressText = document.getElementById('webAudioProgressText');
        const webAudioPlayer = document.getElementById('webAudioPlayer');
        const webAudioTranscript = document.getElementById('webAudioTranscript');

        let audioContext;
        let analyser;
        let microphone;
        let animationId;

        // Check browser support
        if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
            const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
            recognition = new SpeechRecognition();
            
            recognition.continuous = true;
            recognition.interimResults = true;
            recognition.lang = 'fa-IR';
            
            recognition.onstart = () => {
                startBtn.disabled = true;
                stopBtn.disabled = false;
                startBtn.classList.add('recording');
                status.innerHTML = '<div class="status listening">🎤 در حال گوش دادن...</div>';
            };
            
            recognition.onresult = (event) => {
                let finalTranscript = '';
                let interimTranscript = '';
                
                for (let i = event.resultIndex; i < event.results.length; i++) {
                    const transcriptPart = event.results[i][0].transcript;
                    if (event.results[i].isFinal) {
                        finalTranscript += transcriptPart;
                    } else {
                        interimTranscript += transcriptPart;
                    }
                }
                
                transcript.value = finalTranscript + interimTranscript;
            };
            
            recognition.onerror = (event) => {
                status.innerHTML = `<div class="status error">❌ خطا: ${event.error}</div>`;
                resetButtons();
            };
            
            recognition.onend = () => {
                status.innerHTML = '<div class="status">✅ ضبط متوقف شد</div>';
                resetButtons();
            };
            
            startBtn.onclick = () => {
                recognition.lang = langSelect.value;
                recognition.start();
            };
            
            stopBtn.onclick = () => {
                recognition.stop();
            };
            
        } else {
            status.innerHTML = '<div class="status error">❌ مرورگر شما از Speech Recognition پشتیبانی نمی‌کند</div>';
            startBtn.disabled = true;
        }

        function resetButtons() {
            startBtn.disabled = false;
            stopBtn.disabled = true;
            startBtn.classList.remove('recording');
        }

        // Test microphone function
        testMicBtn.onclick = async () => {
            try {
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                audioContext = new (window.AudioContext || window.webkitAudioContext)();
                analyser = audioContext.createAnalyser();
                microphone = audioContext.createMediaStreamSource(stream);
                
                analyser.fftSize = 256;
                microphone.connect(analyser);
                
                const bufferLength = analyser.frequencyBinCount;
                const dataArray = new Uint8Array(bufferLength);
                
                function updateVolume() {
                    analyser.getByteFrequencyData(dataArray);
                    let sum = 0;
                    for (let i = 0; i < bufferLength; i++) {
                        sum += dataArray[i];
                    }
                    const average = sum / bufferLength;
                    const percentage = (average / 255) * 100;
                    
                    volumeBar.style.width = percentage + '%';
                    volumeText.textContent = `سطح صدا: ${Math.round(percentage)}%`;
                    
                    if (percentage > 5) {
                        status.innerHTML = '<div class="status listening">✅ میکروفن کار می‌کند!</div>';
                    }
                    
                    animationId = requestAnimationFrame(updateVolume);
                }
                
                updateVolume();
                status.innerHTML = '<div class="status listening">🎤 تست میکروفن... صحبت کنید</div>';
                
                // Stop test after 10 seconds
                setTimeout(() => {
                    if (animationId) {
                        cancelAnimationFrame(animationId);
                    }
                    if (audioContext) {
                        audioContext.close();
                    }
                    stream.getTracks().forEach(track => track.stop());
                    volumeBar.style.width = '0%';
                    volumeText.textContent = 'تست تمام شد';
                }, 10000);
                
            } catch (error) {
                status.innerHTML = '<div class="status error">❌ خطا در دسترسی به میکروفن: ' + error.message + '</div>';
            }
        };

        // Audio File Processing Functions
        audioFile.onchange = (event) => {
            const file = event.target.files[0];
            if (file) {
                const url = URL.createObjectURL(file);
                audioPlayer.src = url;
                audioPlayer.style.display = 'block';
                processAudioBtn.disabled = false;
                audioStatus.innerHTML = '<div class="status">📁 فایل آماده پردازش است</div>';
            }
        };

        processAudioBtn.onclick = async () => {
            if (!audioFile.files[0]) return;
            
            try {
                // Check microphone first
                const stream = await navigator.mediaDevices.getUserMedia({ audio: true });
                stream.getTracks().forEach(track => track.stop()); // Stop the test stream
                
                // Setup audio recognition
                if ('webkitSpeechRecognition' in window || 'SpeechRecognition' in window) {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    audioRecognition = new SpeechRecognition();
                    
                    audioRecognition.continuous = true;
                    audioRecognition.interimResults = true;
                    audioRecognition.lang = langSelect.value;
                    audioRecognition.maxAlternatives = 1;
                    
                    let finalTranscript = '';
                    
                    audioRecognition.onstart = () => {
                        processAudioBtn.disabled = true;
                        stopProcessBtn.disabled = false;
                        audioStatus.innerHTML = '<div class="status listening">🎤 آماده‌سازی پردازش...</div>';
                        audioTranscript.value = '';
                        
                        // Start playing audio after recognition starts
                        setTimeout(() => {
                            audioPlayer.currentTime = 0;
                            audioPlayer.volume = 0.8; // Set volume to 80%
                            audioPlayer.play();
                            audioStatus.innerHTML = '<div class="status listening">🎵 در حال پخش و پردازش فایل...</div>';
                        }, 1500);
                    };
                    
                    audioRecognition.onresult = (event) => {
                        let interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const transcriptPart = event.results[i][0].transcript;
                            if (event.results[i].isFinal) {
                                finalTranscript += transcriptPart + ' ';
                            } else {
                                interimTranscript += transcriptPart;
                            }
                        }
                        
                        audioTranscript.value = finalTranscript + interimTranscript;
                        
                        // Show progress
                        const currentTime = audioPlayer.currentTime;
                        const duration = audioPlayer.duration;
                        const progress = duration ? Math.round((currentTime / duration) * 100) : 0;
                        audioStatus.innerHTML = `<div class="status listening">🎵 پردازش: ${progress}% (${Math.round(currentTime)}s / ${Math.round(duration)}s)</div>`;
                    };
                    
                    audioRecognition.onerror = (event) => {
                        let errorMsg = 'خطای نامشخص';
                        switch(event.error) {
                            case 'no-speech':
                                errorMsg = 'صدایی تشخیص داده نشد - صدای سیستم را بالا ببرید';
                                break;
                            case 'audio-capture':
                                errorMsg = 'مشکل در دسترسی به میکروفن';
                                break;
                            case 'not-allowed':
                                errorMsg = 'دسترسی به میکروفن مجاز نیست';
                                break;
                            case 'network':
                                errorMsg = 'مشکل اتصال شبکه';
                                break;
                            default:
                                errorMsg = event.error;
                        }
                        audioStatus.innerHTML = `<div class="status error">❌ ${errorMsg}</div>`;
                        resetAudioButtons();
                    };
                    
                    audioRecognition.onend = () => {
                        if (finalTranscript.trim()) {
                            audioStatus.innerHTML = '<div class="status">✅ پردازش با موفقیت تمام شد</div>';
                        } else {
                            audioStatus.innerHTML = '<div class="status error">⚠️ متنی تشخیص داده نشد - تنظیمات صدا را بررسی کنید</div>';
                        }
                        resetAudioButtons();
                        audioPlayer.pause();
                    };
                    
                    // Start recognition
                    audioRecognition.start();
                    
                    // Stop recognition when audio ends
                    audioPlayer.onended = () => {
                        setTimeout(() => {
                            if (audioRecognition) {
                                audioRecognition.stop();
                            }
                        }, 3000); // Wait 3 seconds after audio ends
                    };
                    
                } else {
                    audioStatus.innerHTML = '<div class="status error">❌ مرورگر از Speech Recognition پشتیبانی نمی‌کند</div>';
                }
                
            } catch (error) {
                audioStatus.innerHTML = `<div class="status error">❌ خطا در دسترسی به میکروفن: ${error.message}</div>`;
                resetAudioButtons();
            }
        };

        stopProcessBtn.onclick = () => {
            if (audioRecognition) {
                audioRecognition.stop();
            }
            audioPlayer.pause();
            resetAudioButtons();
        };

        function resetAudioButtons() {
            processAudioBtn.disabled = false;
            stopProcessBtn.disabled = true;
        }

        // Web Audio API Functions
        webAudioFile.onchange = (event) => {
            const file = event.target.files[0];
            if (file) {
                webAudioStatus.innerHTML = '<div class="status">📁 فایل آماده پردازش با Web Audio API</div>';
                processWebAudioBtn.disabled = false;
            }
        };

        processWebAudioBtn.onclick = async () => {
            const file = webAudioFile.files[0];
            if (!file) return;
            
            try {
                processWebAudioBtn.disabled = true;
                stopWebAudioBtn.disabled = false;
                webAudioProgress.style.display = 'block';
                webAudioStatus.innerHTML = '<div class="status listening">🎧 در حال پردازش با Web Audio API...</div>';
                
                // Create audio context
                const audioContext = new (window.AudioContext || window.webkitAudioContext)();
                
                // Read file as ArrayBuffer
                const arrayBuffer = await file.arrayBuffer();
                webAudioProgressBar.style.width = '25%';
                webAudioProgressText.textContent = 'خواندن فایل: 25%';
                
                // Decode audio data
                const audioBuffer = await audioContext.decodeAudioData(arrayBuffer);
                webAudioProgressBar.style.width = '50%';
                webAudioProgressText.textContent = 'پردازش صوت: 50%';
                
                // Convert to WAV blob
                const wavBlob = await audioBufferToWav(audioBuffer);
                const audioUrl = URL.createObjectURL(wavBlob);
                
                webAudioProgressBar.style.width = '75%';
                webAudioProgressText.textContent = 'تبدیل فرمت: 75%';
                
                // Setup audio player
                webAudioPlayer.src = audioUrl;
                webAudioPlayer.style.display = 'block';
                
                webAudioProgressBar.style.width = '100%';
                webAudioProgressText.textContent = 'آماده تشخیص: 100%';
                
                // Process with speech recognition
                await processWithWebAudio(audioUrl);
                
                webAudioProgress.style.display = 'none';
                
            } catch (error) {
                webAudioStatus.innerHTML = `<div class="status error">❌ خطا در پردازش: ${error.message}</div>`;
                webAudioProgress.style.display = 'none';
                resetWebAudioButtons();
            }
        };

        async function audioBufferToWav(buffer) {
            const length = buffer.length;
            const sampleRate = buffer.sampleRate;
            const numberOfChannels = buffer.numberOfChannels;
            
            // Convert to mono
            const monoBuffer = new Float32Array(length);
            if (numberOfChannels === 1) {
                monoBuffer.set(buffer.getChannelData(0));
            } else {
                const leftChannel = buffer.getChannelData(0);
                const rightChannel = buffer.getChannelData(1);
                for (let i = 0; i < length; i++) {
                    monoBuffer[i] = (leftChannel[i] + rightChannel[i]) / 2;
                }
            }
            
            // Create WAV file
            const wavBuffer = new ArrayBuffer(44 + length * 2);
            const view = new DataView(wavBuffer);
            
            // WAV header
            const writeString = (offset, string) => {
                for (let i = 0; i < string.length; i++) {
                    view.setUint8(offset + i, string.charCodeAt(i));
                }
            };
            
            writeString(0, 'RIFF');
            view.setUint32(4, 36 + length * 2, true);
            writeString(8, 'WAVE');
            writeString(12, 'fmt ');
            view.setUint32(16, 16, true);
            view.setUint16(20, 1, true);
            view.setUint16(22, 1, true);
            view.setUint32(24, sampleRate, true);
            view.setUint32(28, sampleRate * 2, true);
            view.setUint16(32, 2, true);
            view.setUint16(34, 16, true);
            writeString(36, 'data');
            view.setUint32(40, length * 2, true);
            
            // Convert float samples to 16-bit PCM
            let offset = 44;
            for (let i = 0; i < length; i++) {
                const sample = Math.max(-1, Math.min(1, monoBuffer[i]));
                view.setInt16(offset, sample * 0x7FFF, true);
                offset += 2;
            }
            
            return new Blob([wavBuffer], { type: 'audio/wav' });
        }

        async function processWithWebAudio(audioUrl) {
            return new Promise((resolve, reject) => {
                try {
                    const SpeechRecognition = window.SpeechRecognition || window.webkitSpeechRecognition;
                    const recognition = new SpeechRecognition();
                    
                    recognition.continuous = true;
                    recognition.interimResults = true;
                    recognition.lang = langSelect.value;
                    recognition.maxAlternatives = 3;
                    
                    let finalTranscript = '';
                    const audio = new Audio(audioUrl);
                    
                    recognition.onstart = () => {
                        webAudioStatus.innerHTML = '<div class="status listening">🎤 شروع تشخیص گفتار...</div>';
                        setTimeout(() => {
                            audio.volume = 1.0;
                            audio.play();
                        }, 1000);
                    };
                    
                    recognition.onresult = (event) => {
                        let interimTranscript = '';
                        
                        for (let i = event.resultIndex; i < event.results.length; i++) {
                            const result = event.results[i];
                            const transcriptPart = result[0].transcript;
                            
                            if (result.isFinal) {
                                finalTranscript += transcriptPart + ' ';
                            } else {
                                interimTranscript += transcriptPart;
                            }
                        }
                        
                        webAudioTranscript.value = finalTranscript + interimTranscript;
                        
                        // Show progress
                        const progress = audio.duration ? Math.round((audio.currentTime / audio.duration) * 100) : 0;
                        webAudioStatus.innerHTML = `<div class="status listening">🎵 پردازش: ${progress}% - ${Math.round(audio.currentTime)}s</div>`;
                    };
                    
                    recognition.onerror = (event) => {
                        webAudioStatus.innerHTML = `<div class="status error">❌ خطا: ${event.error}</div>`;
                        reject(event.error);
                    };
                    
                    recognition.onend = () => {
                        if (finalTranscript.trim()) {
                            webAudioStatus.innerHTML = '<div class="status">🎉 پردازش با Web Audio API کامل شد!</div>';
                        } else {
                            webAudioStatus.innerHTML = '<div class="status error">⚠️ متنی تشخیص نشد</div>';
                        }
                        resetWebAudioButtons();
                        resolve();
                    };
                    
                    audio.onended = () => {
                        setTimeout(() => recognition.stop(), 3000);
                    };
                    
                    recognition.start();
                    
                } catch (error) {
                    reject(error);
                }
            });
        }

        stopWebAudioBtn.onclick = () => {
            webAudioStatus.innerHTML = '<div class="status">⏹️ پردازش متوقف شد</div>';
            resetWebAudioButtons();
        };

        function resetWebAudioButtons() {
            processWebAudioBtn.disabled = false;
            stopWebAudioBtn.disabled = true;
        }

        // Speech Synthesis
        const textToSpeak = document.getElementById('textToSpeak');
        const speakBtn = document.getElementById('speakBtn');
        const pauseBtn = document.getElementById('pauseBtn');
        const voiceSelect = document.getElementById('voiceSelect');
        const rateSlider = document.getElementById('rateSlider');
        const volumeSlider = document.getElementById('volumeSlider');

        let voices = [];
        let currentUtterance = null;

        function loadVoices() {
            voices = speechSynthesis.getVoices();
            voiceSelect.innerHTML = '';
            
            voices.forEach((voice, index) => {
                const option = document.createElement('option');
                option.value = index;
                option.textContent = `${voice.name} (${voice.lang})`;
                if (voice.lang.includes('fa') || voice.lang.includes('FA')) {
                    option.selected = true;
                }
                voiceSelect.appendChild(option);
            });
        }

        // Load voices when available
        speechSynthesis.onvoiceschanged = loadVoices;
        loadVoices();

        speakBtn.onclick = () => {
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
            }
            
            const text = textToSpeak.value.trim();
            if (!text) return;
            
            currentUtterance = new SpeechSynthesisUtterance(text);
            currentUtterance.voice = voices[voiceSelect.value];
            currentUtterance.rate = parseFloat(rateSlider.value);
            currentUtterance.volume = parseFloat(volumeSlider.value);
            
            currentUtterance.onstart = () => {
                speakBtn.textContent = '🔊 در حال خواندن...';
                speakBtn.disabled = true;
            };
            
            currentUtterance.onend = () => {
                speakBtn.textContent = 'خواندن متن';
                speakBtn.disabled = false;
            };
            
            currentUtterance.onerror = () => {
                speakBtn.textContent = 'خواندن متن';
                speakBtn.disabled = false;
            };
            
            speechSynthesis.speak(currentUtterance);
        };

        pauseBtn.onclick = () => {
            if (speechSynthesis.speaking) {
                speechSynthesis.cancel();
                speakBtn.textContent = 'خواندن متن';
                speakBtn.disabled = false;
            }
        };

        // Update sliders display
        rateSlider.oninput = () => {
            rateSlider.nextElementSibling.textContent = rateSlider.value;
        };
        
        volumeSlider.oninput = () => {
            volumeSlider.nextElementSibling.textContent = volumeSlider.value;
        };
    </script>
</body>
</html>